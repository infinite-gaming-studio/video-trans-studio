{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "description"
      },
      "source": [
        "# ğŸ¬ Video Trans Studio - AI è§†é¢‘é…éŸ³ä¸å£å‹åŒæ­¥\n",
        "### æ ¸å¿ƒèƒ½åŠ›ï¼š\n",
        "- **ASR**: Faster-Whisper (Large-v3)\n",
        "- **Translation**: NLLB-200 (HuggingFace Local)\n",
        "- **TTS**: Index-TTS2 (Zero-shot Voice Cloning)\n",
        "- **LipSync**: Wav2Lip-GAN\n",
        "\n",
        "> **è¿è¡Œç¯å¢ƒå»ºè®®**ï¼šGoogle Colab Tesla T4 (16GB VRAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "check-env"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "ğŸ’» ç³»ç»Ÿç¡¬ä»¶ç¯å¢ƒ\n",
            "==================================================\n",
            "æ“ä½œç³»ç»Ÿ: Linux 6.6.105+\n",
            "å¤„ç†å™¨: x86_64\n",
            "ç‰©ç†æ ¸å¿ƒæ•°: 1\n",
            "é€»è¾‘æ ¸å¿ƒæ•°: 2\n",
            "æ€»å†…å­˜: 12.67GB\n",
            "\n",
            "==================================================\n",
            "ğŸš€ æ˜¾å¡ (GPU) ç¯å¢ƒ\n",
            "==================================================\n",
            "GPU 0: Tesla T4\n",
            "  - æ˜¾å­˜æ€»é‡: 14.74 GB\n",
            "  - è®¡ç®—èƒ½åŠ›: 7.5\n",
            "CUDA ç‰ˆæœ¬: 12.6\n",
            "cuDNN ç‰ˆæœ¬: 91002\n",
            "\n",
            "==================================================\n",
            "ğŸ è½¯ä»¶å¼€å‘ç¯å¢ƒ\n",
            "==================================================\n",
            "Python ç‰ˆæœ¬: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PyTorch ç‰ˆæœ¬: 2.9.0+cu126\n",
            "å½“å‰è·¯å¾„: /content\n",
            "Sat Jan 31 07:21:42 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# @title ğŸ” 0. ç¯å¢ƒæ£€æŸ¥ (æ’æŸ¥é—®é¢˜ä¸“ç”¨)\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import platform\n",
        "import psutil\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def get_size(bytes, suffix=\"B\"):\n",
        "    factor = 1024\n",
        "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "        if bytes < factor: return f\"{bytes:.2f}{unit}{suffix}\"\n",
        "        bytes /= factor\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"ğŸ’» ç³»ç»Ÿç¡¬ä»¶ç¯å¢ƒ\")\n",
        "print(\"=\"*50)\n",
        "print(f\"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}\")\n",
        "print(f\"å¤„ç†å™¨: {platform.processor()}\")\n",
        "print(f\"ç‰©ç†æ ¸å¿ƒæ•°: {psutil.cpu_count(logical=False)}\")\n",
        "print(f\"é€»è¾‘æ ¸å¿ƒæ•°: {psutil.cpu_count(logical=True)}\")\n",
        "print(f\"æ€»å†…å­˜: {get_size(psutil.virtual_memory().total)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸš€ æ˜¾å¡ (GPU) ç¯å¢ƒ\")\n",
        "print(\"=\"*50)\n",
        "if torch.cuda.is_available():\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        prop = torch.cuda.get_device_properties(i)\n",
        "        print(f\"GPU {i}: {prop.name}\")\n",
        "        print(f\"  - æ˜¾å­˜æ€»é‡: {prop.total_memory / 1024**3:.2f} GB\")\n",
        "        print(f\"  - è®¡ç®—èƒ½åŠ›: {prop.major}.{prop.minor}\")\n",
        "    print(f\"CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
        "    print(f\"cuDNN ç‰ˆæœ¬: {torch.backends.cudnn.version()}\")\n",
        "else:\n",
        "    print(\"âŒ æœªæ£€æµ‹åˆ°å¯ç”¨ GPUï¼Œè¯·åœ¨ 'ä¿®æ”¹' -> 'ç¬”è®°æœ¬è®¾ç½®' ä¸­å¼€å¯ T4 GPU åŠ é€Ÿã€‚\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ è½¯ä»¶å¼€å‘ç¯å¢ƒ\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
        "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
        "print(f\"å½“å‰è·¯å¾„: {os.getcwd()}\")\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "setup"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/video-trans-studio\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (4/4), 600 bytes | 600.00 KiB/s, done.\n",
            "From https://github.com/infinite-gaming-studio/video-trans-studio\n",
            "   7db00da..61d8862  main       -> origin/main\n",
            "Updating 7db00da..61d8862\n",
            "Fast-forward\n",
            " core/lipsync.py | 12 \u001b[32m++++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 10 insertions(+), 2 deletions(-)\n",
            "âœ… ç¯å¢ƒå·²å°±ç»ªï¼ŒTransformers ç‰ˆæœ¬: 4.38.0\n"
          ]
        }
      ],
      "source": [
        "# @title ğŸš€ 1. ç¯å¢ƒåˆå§‹åŒ–\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. ç¡®ä¿åœ¨ /content ç›®å½•ä¸‹æ“ä½œ\n",
        "os.chdir('/content')\n",
        "\n",
        "# 2. å…‹éš†é¡¹ç›®å¹¶è¿›å…¥\n",
        "if not os.path.exists('video-trans-studio'):\n",
        "    !git clone https://github.com/infinite-gaming-studio/video-trans-studio.git\n",
        "\n",
        "%cd video-trans-studio\n",
        "!git fetch --all\n",
        "!git reset --hard origin/main\n",
        "!git pull\n",
        "\n",
        "# 3. æ™ºèƒ½ç¯å¢ƒæ£€æµ‹ä¸å®‰è£…\n",
        "\n",
        "if not os.path.exists(env_marker):\n",
        "    print(\"â³ æ­£åœ¨è¿›è¡Œé¦–æ¬¡ç¯å¢ƒå®‰è£… (å¤§çº¦ 3-5 åˆ†é’Ÿ)...\")\n",
        "    !bash setup_colab.sh\n",
        "    with open(env_marker, 'w') as f: f.write('done')\n",
        "    \n",
        "    print(\"\\n\" + \"!\"*50)\n",
        "    print(\"âš ï¸ ç¯å¢ƒå®‰è£…å·²å®Œæˆï¼\")\n",
        "    print(\"âš ï¸ ç”±äº Colab æœºåˆ¶ï¼Œè¯·åŠ¡å¿…æ‰‹åŠ¨ç‚¹å‡»ä¸Šæ–¹èœå•æ : \")\n",
        "    print(\"   'è¿è¡Œæ—¶' -> 'é‡æ–°å¯åŠ¨ä¼šè¯' (Runtime -> Restart Session)\")\n",
        "    print(\"âš ï¸ é‡å¯åï¼Œç›´æ¥ä» 'ç¬¬ 2 æ­¥' å¼€å§‹è¿è¡Œå³å¯ã€‚\")\n",
        "    print(\"!\"*50)\n",
        "else:\n",
        "    try:\n",
        "        import transformers\n",
        "        print(\"âœ… ç¯å¢ƒå·²å°±ç»ªï¼ŒTransformers ç‰ˆæœ¬:\", transformers.__version__)\n",
        "    except ImportError:\n",
        "        print(\"âŒ ç¯å¢ƒè™½ç„¶å·²å®‰è£…ï¼Œä½†å°šæœªé‡å¯ä¼šè¯ï¼Œè¯·ç‚¹å‡» 'è¿è¡Œæ—¶' -> 'é‡æ–°å¯åŠ¨ä¼šè¯'ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "upload"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… æˆåŠŸå®šä½æœåŠ¡å™¨æ ¹ç›®å½•ç´ æ: /content/sample_video/bilibili_BV1ZzzDBKEhF_852x480.mp4\n",
            "ğŸ•’ æœ€æ–°ä¸Šä¼ æ—¶é—´: 1769838529.7385452\n"
          ]
        }
      ],
      "source": [
        "# @title ğŸ“‚ 2. é€‰æ‹©ç´ æ\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# æ ¸å¿ƒé€»è¾‘ï¼šè‡ªåŠ¨æŠ“å–æœåŠ¡å™¨æ ¹ç›®å½•ä¸‹ sample_video æ–‡ä»¶å¤¹ä¸­æœ€æ–°ä¸Šä¼ çš„è§†é¢‘\n",
        "# åœ¨ Colab ä¸­ï¼Œæ ¹ç›®å½•é€šå¸¸æ˜¯ /content\n",
        "colab_root = Path('/content')\n",
        "sample_dir = colab_root / 'sample_video'\n",
        "\n",
        "# å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä¸åœ¨ Colab ç¯å¢ƒï¼Œå°è¯•æŸ¥æ‰¾å½“å‰ç›®å½•ä¸‹çš„ sample_video\n",
        "if not sample_dir.exists():\n",
        "    sample_dir = Path('sample_video')\n",
        "\n",
        "video_path = None\n",
        "\n",
        "if sample_dir.exists():\n",
        "    # æ”¯æŒçš„è§†é¢‘æ ¼å¼\n",
        "    valid_extensions = ['*.mp4', '*.mov', '*.avi', '*.mkv', '*.webm']\n",
        "    video_files = []\n",
        "    for ext in valid_extensions:\n",
        "        video_files.extend(glob.glob(str(sample_dir / ext)))\n",
        "    \n",
        "    if video_files:\n",
        "        # æŒ‰ä¿®æ”¹æ—¶é—´ï¼ˆmtimeï¼‰æ’åºï¼Œå–æœ€æ–°çš„ä¸€ä¸ª\n",
        "        video_path = max(video_files, key=os.path.getmtime)\n",
        "        print(f\"âœ… æˆåŠŸå®šä½æœåŠ¡å™¨æ ¹ç›®å½•ç´ æ: {video_path}\")\n",
        "        print(f\"ğŸ•’ æœ€æ–°ä¸Šä¼ æ—¶é—´: {os.path.getmtime(video_path)}\")\n",
        "    else:\n",
        "        print(f\"âŒ åœ¨ {sample_dir} æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶ã€‚\")\n",
        "else:\n",
        "    print(f\"âŒ æœªæ‰¾åˆ°ç›®å½•: {sample_dir.absolute()}\")\n",
        "    print(\"ğŸ’¡ è¯·ç¡®ä¿åœ¨ Colab å·¦ä¾§ä¾§è¾¹æ çš„æ ¹ç›®å½•ï¼ˆ/contentï¼‰ä¸‹åˆ›å»ºäº† sample_video æ–‡ä»¶å¤¹ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "run"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: /content/sample_video/bilibili_BV1ZzzDBKEhF_852x480.mp4\n",
            "âœ… Running on: CUDA\n",
            "ğŸš€ GPU: Tesla T4\n",
            "ğŸ’¾ VRAM: 15.83 GB\n",
            "ğŸ“‚ Output Dir: /content/video-trans-studio/output\n",
            "â³ [PROGRESS] |--------------------| 0% | STEP: Initializing (Waiting) | Step Time: 0.0s | Total: 0.0sğŸ¬ Extracting audio from /content/sample_video/bilibili_BV1ZzzDBKEhF_852x480.mp4...\n",
            "â³ [PROGRESS] |--------------------| 0% | STEP: Audio Extraction (Extracting Wav) | Step Time: 5.0s | Total: 5.0sâœ… Audio extracted to: /content/video-trans-studio/temp/original_audio.wav\n",
            "â³ Loading Whisper Model (large-v3)...\n",
            "â³ [PROGRESS] |â–ˆâ–ˆâ–ˆâ–ˆ----------------| 20% | STEP: ASR Transcription (Whisper Large-v3) | Step Time: 9.3s | Total: 15.0s"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â³ [PROGRESS] |â–ˆâ–ˆâ–ˆâ–ˆ----------------| 20% | STEP: ASR Transcription (Whisper Large-v3) | Step Time: 13.3s | Total: 19.0sâœ… Whisper Model Loaded.\n",
            "ğŸ™ï¸ Transcribing: /content/video-trans-studio/temp/original_audio.wav...\n",
            "â³ [PROGRESS] |â–ˆâ–ˆâ–ˆâ–ˆ----------------| 20% | STEP: ASR Transcription (Whisper Large-v3) | Step Time: 103.5s | Total: 109.2sâœ… Transcription complete. Detected language: zh\n",
            "ğŸ—‘ï¸ Whisper Model Unloaded.\n",
            "ğŸŒ Translating 324 segments...\n",
            "â³ [PROGRESS] |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ------------| 40% | STEP: Translation (NLLB to en) | Step Time: 25.1s | Total: 135.3sğŸ—£ï¸ Generating TTS audio for 324 segments via Edge-TTS...\n",
            "â³ Downloading segments in parallel...\n",
            "â³ [PROGRESS] |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------| 60% | STEP: TTS Generation (Edge-TTS Generating) | Step Time: 21.3s | Total: 157.3sğŸ§© Combining audio segments with proper timing...\n",
            "â³ [PROGRESS] |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ--------| 60% | STEP: TTS Generation (Edge-TTS Generating) | Step Time: 83.4s | Total: 219.5sâœ… Audio generated: /content/video-trans-studio/output/bilibili_BV1ZzzDBKEhF_852x480/dubbed_audio.wav\n",
            "ğŸ‘„ Starting LipSync (Wav2Lip) - This might take a while on T4...\n",
            "ğŸ› Debug executing command: python Wav2Lip/inference.py --checkpoint_path /content/video-trans-studio/checkpoints/wav2lip_gan.pth --face /content/sample_video/bilibili_BV1ZzzDBKEhF_852x480.mp4 --audio /content/video-trans-studio/output/bilibili_BV1ZzzDBKEhF_852x480/dubbed_audio.wav --outfile /content/video-trans-studio/output/bilibili_BV1ZzzDBKEhF_852x480/final_bilibili_BV1ZzzDBKEhF_852x480_en.mp4 --pads 0 20 0 0\n",
            "â³ [PROGRESS] |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ----| 80% | STEP: Lip-Syncing (Wav2Lip Syncing) | Step Time: 1.2s | Total: 221.5sâŒ LipSync failed with return code 1\n",
            "ğŸ” Error Output:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/video-trans-studio/Wav2Lip/inference.py\", line 3, in <module>\n",
            "    import scipy, cv2, os, sys, argparse, audio\n",
            "  File \"/content/video-trans-studio/Wav2Lip/audio.py\", line 1, in <module>\n",
            "    import librosa\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/librosa/__init__.py\", line 211, in <module>\n",
            "    from . import core\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/librosa/core/__init__.py\", line 9, in <module>\n",
            "    from .constantq import *  # pylint: disable=wildcard-import\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/librosa/core/constantq.py\", line 1058, in <module>\n",
            "    dtype=np.complex,\n",
            "          ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\", line 394, in __getattr__\n",
            "    raise AttributeError(__former_attrs__[attr])\n",
            "AttributeError: module 'numpy' has no attribute 'complex'.\n",
            "`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\n",
            "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
            "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'complex64'?\n",
            "\n",
            "ğŸ“œ Standard Output:\n",
            "\n",
            "\n",
            "\n",
            "ğŸ‰ Pipeline Finished Successfully!\n",
            "ğŸ“¦ Final Result: /content/video-trans-studio/output/bilibili_BV1ZzzDBKEhF_852x480/final_bilibili_BV1ZzzDBKEhF_852x480_en.mp4\n",
            "ğŸ“„ Also check: /content/video-trans-studio/output/bilibili_BV1ZzzDBKEhF_852x480/dubbed_audio.wav\n",
            "\n",
            "âœ¨ å¤„ç†å…¨æµç¨‹ç»“æŸï¼\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title âš™ï¸ 3. è¿è¡Œå…¨è‡ªåŠ¨æµæ°´çº¿\n",
        "target_language = \"en\" # @param [\"zh-cn\", \"en\", \"es\", \"fr\", \"ja\"]\n",
        "use_local_translation = True # @param {type:\"boolean\"}\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import importlib\n",
        "import os\n",
        "\n",
        "# ç¡®ä¿åœ¨é¡¹ç›®ç›®å½•ä¸­è¿è¡Œ\n",
        "if os.getcwd() != '/content/video-trans-studio':\n",
        "    %cd /content/video-trans-studio\n",
        "\n",
        "# å¼ºåˆ¶é‡è½½è‡ªå®šä¹‰æ¨¡å—ï¼Œé˜²æ­¢ä»£ç ç¼“å­˜ (First Principles: Memory vs Disk Sync)\n",
        "# è¿™ä¸€æ­¥è‡³å…³é‡è¦ï¼Œå› ä¸º Notebook ä¼šç¼“å­˜ import çš„æ¨¡å—\n",
        "modules_to_reload = ['main', 'config', 'core.tts', 'core.lipsync', 'core.utils', 'core.asr', 'core.audio', 'core.translator']\n",
        "for module in modules_to_reload:\n",
        "    if module in sys.modules:\n",
        "        del sys.modules[module]\n",
        "\n",
        "# æ£€æŸ¥æ ¸å¿ƒä¾èµ–ï¼Œå¦‚æœæŠ¥é”™åˆ™æä¾›ä¿®å¤æ–¹æ¡ˆ\n",
        "try:\n",
        "    from transformers import pipeline\n",
        "    from main import run_pipeline\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ æ¨¡å—åŠ è½½å¤±è´¥: {e}\")\n",
        "    print(\"\\nğŸ”„ å°è¯•è‡ªåŠ¨ç´§æ€¥ä¿®å¤ç¯å¢ƒ...\")\n",
        "    !pip install transformers==4.38.0 --force-reinstall\n",
        "    print(\"âš ï¸ ç¯å¢ƒå·²é‡ç½®ï¼Œè¯·åŠ¡å¿…ç‚¹å‡»ä¸Šæ–¹ 'è¿è¡Œæ—¶' -> 'é‡æ–°å¯åŠ¨ä¼šè¯'ï¼Œç„¶åå†æ¬¡è¿è¡Œæ­¤å•å…ƒæ ¼ã€‚\")\n",
        "    sys.exit()\n",
        "\n",
        "# å¼ºåˆ¶æ¸…ç†æ˜¾å­˜å¹¶æ‰§è¡Œ\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "if 'video_path' in locals() and video_path:\n",
        "    # ä½¿ç”¨ print å®æ—¶åˆ·æ–°è¾“å‡º\n",
        "    print(f\"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}\")\n",
        "    # é¡¶å±‚ await è°ƒç”¨å¼‚æ­¥å‡½æ•°\n",
        "    await run_pipeline(video_path, target_lang=target_language)\n",
        "else:\n",
        "    print(\"âŒ é”™è¯¯ï¼šæœªå®šä¹‰ video_pathï¼Œè¯·å…ˆæˆåŠŸè¿è¡Œ 'ç¬¬ 2 æ­¥'ã€‚\")\n",
        "\n",
        "print(\"\\nâœ¨ å¤„ç†å…¨æµç¨‹ç»“æŸï¼\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preview"
      },
      "outputs": [],
      "source": [
        "# @title ğŸ“º 4. é¢„è§ˆç»“æœ\n",
        "import os\n",
        "import glob\n",
        "from IPython.display import Video\n",
        "\n",
        "output_dir = 'output'\n",
        "# é€’å½’æŸ¥æ‰¾æ‰€æœ‰ä»¥ final_ å¼€å¤´çš„ mp4 æ–‡ä»¶\n",
        "final_videos = glob.glob(os.path.join(output_dir, '**', 'final_*.mp4'), recursive=True)\n",
        "\n",
        "if final_videos:\n",
        "    # æŒ‰ç…§æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åºï¼Œå±•ç¤ºæœ€æ–°ç”Ÿæˆçš„ä¸€ä¸ª\n",
        "    latest_video = max(final_videos, key=os.path.getmtime)\n",
        "    print(f\"ğŸ¬ å±•ç¤ºæœ€æ–°ç”Ÿæˆçš„è§†é¢‘: {latest_video}\")\n",
        "    display(Video(latest_video, embed=True, width=600))\n",
        "else:\n",
        "    print(\"âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶ã€‚\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "description"
      },
      "source": [
        "# ğŸ¬ Video Trans Studio - AI è§†é¢‘é…éŸ³ä¸å£å‹åŒæ­¥\n",
        "### æ ¸å¿ƒèƒ½åŠ›ï¼š\n",
        "- **ASR**: Faster-Whisper (Large-v3)\n",
        "- **Translation**: NLLB-200 (HuggingFace Local)\n",
        "- **TTS**: Index-TTS2 (Zero-shot Voice Cloning)\n",
        "- **LipSync**: Wav2Lip-GAN\n",
        "\n",
        "> **è¿è¡Œç¯å¢ƒå»ºè®®**ï¼šGoogle Colab Tesla T4 (16GB VRAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "check-env"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "ğŸ’» ç³»ç»Ÿç¡¬ä»¶ç¯å¢ƒ\n",
            "==================================================\n",
            "æ“ä½œç³»ç»Ÿ: Linux 6.6.105+\n",
            "å¤„ç†å™¨: x86_64\n",
            "ç‰©ç†æ ¸å¿ƒæ•°: 1\n",
            "é€»è¾‘æ ¸å¿ƒæ•°: 2\n",
            "æ€»å†…å­˜: 12.67GB\n",
            "\n",
            "==================================================\n",
            "ğŸš€ æ˜¾å¡ (GPU) ç¯å¢ƒ\n",
            "==================================================\n",
            "GPU 0: Tesla T4\n",
            "  - æ˜¾å­˜æ€»é‡: 14.74 GB\n",
            "  - è®¡ç®—èƒ½åŠ›: 7.5\n",
            "CUDA ç‰ˆæœ¬: 12.6\n",
            "cuDNN ç‰ˆæœ¬: 91002\n",
            "\n",
            "==================================================\n",
            "ğŸ è½¯ä»¶å¼€å‘ç¯å¢ƒ\n",
            "==================================================\n",
            "Python ç‰ˆæœ¬: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PyTorch ç‰ˆæœ¬: 2.9.0+cu126\n",
            "å½“å‰è·¯å¾„: /content\n",
            "Sat Jan 31 06:20:41 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# @title ğŸ” 0. ç¯å¢ƒæ£€æŸ¥ (æ’æŸ¥é—®é¢˜ä¸“ç”¨)\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import platform\n",
        "import psutil\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def get_size(bytes, suffix=\"B\"):\n",
        "    factor = 1024\n",
        "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
        "        if bytes < factor: return f\"{bytes:.2f}{unit}{suffix}\"\n",
        "        bytes /= factor\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"ğŸ’» ç³»ç»Ÿç¡¬ä»¶ç¯å¢ƒ\")\n",
        "print(\"=\"*50)\n",
        "print(f\"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}\")\n",
        "print(f\"å¤„ç†å™¨: {platform.processor()}\")\n",
        "print(f\"ç‰©ç†æ ¸å¿ƒæ•°: {psutil.cpu_count(logical=False)}\")\n",
        "print(f\"é€»è¾‘æ ¸å¿ƒæ•°: {psutil.cpu_count(logical=True)}\")\n",
        "print(f\"æ€»å†…å­˜: {get_size(psutil.virtual_memory().total)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸš€ æ˜¾å¡ (GPU) ç¯å¢ƒ\")\n",
        "print(\"=\"*50)\n",
        "if torch.cuda.is_available():\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        prop = torch.cuda.get_device_properties(i)\n",
        "        print(f\"GPU {i}: {prop.name}\")\n",
        "        print(f\"  - æ˜¾å­˜æ€»é‡: {prop.total_memory / 1024**3:.2f} GB\")\n",
        "        print(f\"  - è®¡ç®—èƒ½åŠ›: {prop.major}.{prop.minor}\")\n",
        "    print(f\"CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n",
        "    print(f\"cuDNN ç‰ˆæœ¬: {torch.backends.cudnn.version()}\")\n",
        "else:\n",
        "    print(\"âŒ æœªæ£€æµ‹åˆ°å¯ç”¨ GPUï¼Œè¯·åœ¨ 'ä¿®æ”¹' -> 'ç¬”è®°æœ¬è®¾ç½®' ä¸­å¼€å¯ T4 GPU åŠ é€Ÿã€‚\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ è½¯ä»¶å¼€å‘ç¯å¢ƒ\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
        "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
        "print(f\"å½“å‰è·¯å¾„: {os.getcwd()}\")\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "setup"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/video-trans-studio\n",
            "â³ æ­£åœ¨è¿›è¡Œé¦–æ¬¡ç¯å¢ƒå®‰è£…...\n",
            "ğŸš€ Starting Video Trans Studio Colab Setup...\n",
            "ğŸ“¦ Installing system dependencies (ffmpeg)...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "ğŸ Installing Python libraries...\n",
            "ğŸ“¥ Downloading AI model weights (Wav2Lip, NLLB, Index-TTS)...\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "âœ… Setup Complete! Ready to process videos.\n",
            "ğŸ’¡ Usage: python main.py your_video.mp4 zh-cn\n",
            "\n",
            "âš ï¸ ç¯å¢ƒå®‰è£…å®Œæˆï¼Œæ­£åœ¨è‡ªåŠ¨é‡å¯å†…æ ¸ä»¥åº”ç”¨æ›´æ”¹...\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# @title ğŸš€ 1. ç¯å¢ƒåˆå§‹åŒ–\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. ç¡®ä¿åœ¨ /content ç›®å½•ä¸‹æ“ä½œ\n",
        "os.chdir('/content')\n",
        "\n",
        "# 2. å…‹éš†é¡¹ç›®å¹¶è¿›å…¥\n",
        "if not os.path.exists('video-trans-studio'):\n",
        "    !git clone https://github.com/infinite-gaming-studio/video-trans-studio.git\n",
        "\n",
        "%cd video-trans-studio\n",
        "\n",
        "# 3. è¿è¡Œå®‰è£…è„šæœ¬ (ä½¿ç”¨æŒä¹…åŒ–æ ‡å¿—æ–‡ä»¶é˜²æ­¢å¾ªç¯)\n",
        "env_marker = '/content/.env_ready'\n",
        "\n",
        "if not os.path.exists(env_marker):\n",
        "    print(\"â³ æ­£åœ¨è¿›è¡Œé¦–æ¬¡ç¯å¢ƒå®‰è£… (å¤§çº¦ 3-5 åˆ†é’Ÿ)...\")\n",
        "    !bash setup_colab.sh\n",
        "    with open(env_marker, 'w') as f: f.write('done')\n",
        "    \n",
        "    print(\"\\n\" + \"!\"*50)\n",
        "    print(\"âš ï¸ ç¯å¢ƒå®‰è£…å·²å®Œæˆï¼\")\n",
        "    print(\"âš ï¸ ç”±äº Colab æœºåˆ¶ï¼Œè¯·åŠ¡å¿…æ‰‹åŠ¨ç‚¹å‡»ä¸Šæ–¹èœå•æ : \")\n",
        "    print(\"   'è¿è¡Œæ—¶' -> 'é‡æ–°å¯åŠ¨ä¼šè¯' (Runtime -> Restart Session)\")\n",
        "    print(\"âš ï¸ é‡å¯åï¼Œç›´æ¥ä» 'ç¬¬ 2 æ­¥' å¼€å§‹è¿è¡Œå³å¯ã€‚\")\n",
        "    print(\"!\"*50)\n",
        "else:\n",
        "    try:\n",
        "        import transformers\n",
        "        print(\"âœ… ç¯å¢ƒå·²å°±ç»ªï¼ŒTransformers ç‰ˆæœ¬:\", transformers.__version__)\n",
        "    except ImportError:\n",
        "        print(\"âŒ ç¯å¢ƒè™½ç„¶å·²å®‰è£…ï¼Œä½†å°šæœªé‡å¯ä¼šè¯ï¼Œè¯·ç‚¹å‡» 'è¿è¡Œæ—¶' -> 'é‡æ–°å¯åŠ¨ä¼šè¯'ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "upload"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… æˆåŠŸå®šä½æœåŠ¡å™¨æ ¹ç›®å½•ç´ æ: /content/sample_video/bilibili_BV1ZzzDBKEhF_852x480.mp4\n",
            "ğŸ•’ æœ€æ–°ä¸Šä¼ æ—¶é—´: 1769838529.7385452\n"
          ]
        }
      ],
      "source": [
        "# @title ğŸ“‚ 2. é€‰æ‹©ç´ æ\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "# æ ¸å¿ƒé€»è¾‘ï¼šè‡ªåŠ¨æŠ“å–æœåŠ¡å™¨æ ¹ç›®å½•ä¸‹ sample_video æ–‡ä»¶å¤¹ä¸­æœ€æ–°ä¸Šä¼ çš„è§†é¢‘\n",
        "# åœ¨ Colab ä¸­ï¼Œæ ¹ç›®å½•é€šå¸¸æ˜¯ /content\n",
        "colab_root = Path('/content')\n",
        "sample_dir = colab_root / 'sample_video'\n",
        "\n",
        "# å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä¸åœ¨ Colab ç¯å¢ƒï¼Œå°è¯•æŸ¥æ‰¾å½“å‰ç›®å½•ä¸‹çš„ sample_video\n",
        "if not sample_dir.exists():\n",
        "    sample_dir = Path('sample_video')\n",
        "\n",
        "video_path = None\n",
        "\n",
        "if sample_dir.exists():\n",
        "    # æ”¯æŒçš„è§†é¢‘æ ¼å¼\n",
        "    valid_extensions = ['*.mp4', '*.mov', '*.avi', '*.mkv', '*.webm']\n",
        "    video_files = []\n",
        "    for ext in valid_extensions:\n",
        "        video_files.extend(glob.glob(str(sample_dir / ext)))\n",
        "    \n",
        "    if video_files:\n",
        "        # æŒ‰ä¿®æ”¹æ—¶é—´ï¼ˆmtimeï¼‰æ’åºï¼Œå–æœ€æ–°çš„ä¸€ä¸ª\n",
        "        video_path = max(video_files, key=os.path.getmtime)\n",
        "        print(f\"âœ… æˆåŠŸå®šä½æœåŠ¡å™¨æ ¹ç›®å½•ç´ æ: {video_path}\")\n",
        "        print(f\"ğŸ•’ æœ€æ–°ä¸Šä¼ æ—¶é—´: {os.path.getmtime(video_path)}\")\n",
        "    else:\n",
        "        print(f\"âŒ åœ¨ {sample_dir} æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶ã€‚\")\n",
        "else:\n",
        "    print(f\"âŒ æœªæ‰¾åˆ°ç›®å½•: {sample_dir.absolute()}\")\n",
        "    print(\"ğŸ’¡ è¯·ç¡®ä¿åœ¨ Colab å·¦ä¾§ä¾§è¾¹æ çš„æ ¹ç›®å½•ï¼ˆ/contentï¼‰ä¸‹åˆ›å»ºäº† sample_video æ–‡ä»¶å¤¹ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "run"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/video-trans-studio\n",
            "ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: /content/sample_video/bilibili_BV1ZzzDBKEhF_852x480.mp4\n",
            "âœ… Running on: CUDA\n",
            "ğŸš€ GPU: Tesla T4\n",
            "ğŸ’¾ VRAM: 15.83 GB\n",
            "ğŸ“‚ Output Dir: /content/video-trans-studio/output\n",
            "ğŸ¬ Extracting audio from /content/sample_video/bilibili_BV1ZzzDBKEhF_852x480.mp4...\n",
            "âœ… Audio extracted to: /content/video-trans-studio/temp/original_audio.wav\n",
            "â³ Loading Whisper Model (large-v3)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Whisper Model Loaded.\n",
            "ğŸ™ï¸ Transcribing: /content/video-trans-studio/temp/original_audio.wav...\n",
            "âœ… Transcription complete. Detected language: zh\n",
            "ğŸ—‘ï¸ Whisper Model Unloaded.\n",
            "ğŸŒ Translating 324 segments...\n",
            "ğŸ—£ï¸ Generating TTS audio via Edge-TTS...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1696696786.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# ä½¿ç”¨ print å®æ—¶åˆ·æ–°è¾“å‡º\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âŒ é”™è¯¯ï¼šæœªå®šä¹‰ video_pathï¼Œè¯·å…ˆæˆåŠŸè¿è¡Œ 'ç¬¬ 2 æ­¥'ã€‚\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/video-trans-studio/main.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(video_path, target_lang)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mtts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTTSProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdubbed_audio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEMP_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"dubbed_audio.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_full_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated_segments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdubbed_audio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# 5. LipSync (Wav2Lip)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/video-trans-studio/core/tts.py\u001b[0m in \u001b[0;36mgenerate_full_audio\u001b[0;34m(self, segments, output_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mcurrent_time_ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msilence_duration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_segment_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mseg_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_mp3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_segment_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcombined_audio\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mseg_audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# fail fast with short traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    192\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ],
      "source": [
        "# @title âš™ï¸ 3. è¿è¡Œå…¨è‡ªåŠ¨æµæ°´çº¿\n",
        "target_language = \"en\" # @param [\"zh-cn\", \"en\", \"es\", \"fr\", \"ja\"]\n",
        "use_local_translation = True # @param {type:\"boolean\"}\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "import importlib\n",
        "import os\n",
        "\n",
        "# ç¡®ä¿åœ¨é¡¹ç›®ç›®å½•ä¸­è¿è¡Œ\n",
        "if os.getcwd() != '/content/video-trans-studio':\n",
        "    %cd /content/video-trans-studio\n",
        "\n",
        "# æ£€æŸ¥æ ¸å¿ƒä¾èµ–ï¼Œå¦‚æœæŠ¥é”™åˆ™æä¾›ä¿®å¤æ–¹æ¡ˆ\n",
        "try:\n",
        "    from transformers import pipeline\n",
        "    from main import run_pipeline\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ æ¨¡å—åŠ è½½å¤±è´¥: {e}\")\n",
        "    print(\"\\nğŸ”„ å°è¯•è‡ªåŠ¨ç´§æ€¥ä¿®å¤ç¯å¢ƒ...\")\n",
        "    !pip install transformers==4.38.0 --force-reinstall\n",
        "    print(\"âš ï¸ ç¯å¢ƒå·²é‡ç½®ï¼Œè¯·åŠ¡å¿…ç‚¹å‡»ä¸Šæ–¹ 'è¿è¡Œæ—¶' -> 'é‡æ–°å¯åŠ¨ä¼šè¯'ï¼Œç„¶åå†æ¬¡è¿è¡Œæ­¤å•å…ƒæ ¼ã€‚\")\n",
        "    sys.exit()\n",
        "\n",
        "# å¼ºåˆ¶æ¸…ç†æ˜¾å­˜å¹¶æ‰§è¡Œ\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "if 'video_path' in locals() and video_path:\n",
        "    # ä½¿ç”¨ print å®æ—¶åˆ·æ–°è¾“å‡º\n",
        "    print(f\"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}\")\n",
        "    # é¡¶å±‚ await è°ƒç”¨å¼‚æ­¥å‡½æ•°\n",
        "    await run_pipeline(video_path, target_lang=target_language)\n",
        "else:\n",
        "    print(\"âŒ é”™è¯¯ï¼šæœªå®šä¹‰ video_pathï¼Œè¯·å…ˆæˆåŠŸè¿è¡Œ 'ç¬¬ 2 æ­¥'ã€‚\")\n",
        "\n",
        "print(\"\\nâœ¨ å¤„ç†å…¨æµç¨‹ç»“æŸï¼\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preview"
      },
      "outputs": [],
      "source": [
        "# @title ğŸ“º 4. é¢„è§ˆç»“æœ\n",
        "import os\n",
        "import glob\n",
        "from IPython.display import Video\n",
        "\n",
        "output_dir = 'output'\n",
        "# é€’å½’æŸ¥æ‰¾æ‰€æœ‰ä»¥ final_ å¼€å¤´çš„ mp4 æ–‡ä»¶\n",
        "final_videos = glob.glob(os.path.join(output_dir, '**', 'final_*.mp4'), recursive=True)\n",
        "\n",
        "if final_videos:\n",
        "    # æŒ‰ç…§æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åºï¼Œå±•ç¤ºæœ€æ–°ç”Ÿæˆçš„ä¸€ä¸ª\n",
        "    latest_video = max(final_videos, key=os.path.getmtime)\n",
        "    print(f\"ğŸ¬ å±•ç¤ºæœ€æ–°ç”Ÿæˆçš„è§†é¢‘: {latest_video}\")\n",
        "    display(Video(latest_video, embed=True, width=600))\n",
        "else:\n",
        "    print(\"âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶ã€‚\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
